{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"accelerator":"GPU","colab":{"gpuType":"L4","machine_shape":"hm","provenance":[]},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":0,"nbformat":4,"cells":[{"cell_type":"markdown","source":["## Classification using different prompts\n","Test different propmts to classify stress or no stress using messages from Dreaddit: A Reddit Dataset for Stress Analysis in Social Media. See: https://aclanthology.org/D19-6213.\n","\n","Commonly updated parameters are in the Parameter block below.\n","\n","**test_count:** The number of messages to use in generating prompts.\n","\n","**model_name** The model ID downloaded from Hugging Face.\n","\n","**access_token** The Hugging Face access token.\n","\n","**prompt_function:** Choose your prompt from different prompt functions.\n","\n","**rows_per_set** The number of messages to score in each prompt. The prompt can score multiple messages to reduce resources/time.  Note Dreaddit messages can be large and the resulting prompt can have too much context.  Model accuracy for 1 message per prompt is typically better than 5 messages per prompt but slower.\n","\n"],"metadata":{"id":"NTS-cngWlaWk"}},{"cell_type":"markdown","source":["#### Parameters"],"metadata":{"id":"pLg7K16kkjTn"}},{"cell_type":"code","source":["test_count = 400\n","model_name  = \"microsoft/Phi-3-medium-4K-instruct\"\n","access_token = ''\n","#prompt_function = 'create_dreaddit_prompt'\n","prompt_function = 'create_examples_prompt'\n","rows_per_set = 2"],"metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-13T11:31:51.134374Z","iopub.execute_input":"2025-04-13T11:31:51.134638Z","iopub.status.idle":"2025-04-13T11:31:51.139461Z","shell.execute_reply.started":"2025-04-13T11:31:51.134609Z","shell.execute_reply":"2025-04-13T11:31:51.138227Z"},"id":"rnzlCCCjkjTo"},"outputs":[],"execution_count":null},{"cell_type":"code","source":["# Use PyTorch 2.0 Kernel on Vertex AI\n","\n","# flash attention support\n","#!pip install flash-attn --no-build-isolation\n","\n","!pip install pandas\n","!pip install tqdm\n","!pip install transformers\n","!pip install -U bitsandbytes\n","!pip install accelerate\n"],"metadata":{"id":"n7vUfbHCrTNO","trusted":true,"execution":{"iopub.status.busy":"2025-04-13T11:31:51.140835Z","iopub.execute_input":"2025-04-13T11:31:51.141082Z","iopub.status.idle":"2025-04-13T11:32:11.074416Z","shell.execute_reply.started":"2025-04-13T11:31:51.141057Z","shell.execute_reply":"2025-04-13T11:32:11.073608Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":["from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline, set_seed\n","import accelerate\n","#import bitsandbytes\n","import sys\n","from importlib import reload\n","\n","import pandas as pd\n","import tqdm"],"metadata":{"id":"5GAtLSqOY_ZO","trusted":true,"execution":{"iopub.status.busy":"2025-04-13T11:32:11.075661Z","iopub.execute_input":"2025-04-13T11:32:11.075873Z","iopub.status.idle":"2025-04-13T11:32:31.413940Z","shell.execute_reply.started":"2025-04-13T11:32:11.075854Z","shell.execute_reply":"2025-04-13T11:32:31.413148Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":["### Login to Huggingface"],"metadata":{"id":"MIEuPgd4b6BY"}},{"cell_type":"code","source":["### the safer way\n","#from huggingface_hub import notebook_login\n","#notebook_login()\n","\n","### alternative: https://huggingface.co/settings/tokens\n","from huggingface_hub import login\n","login(access_token)"],"metadata":{"id":"ZuBm3fkPrKR5","trusted":true,"execution":{"iopub.status.busy":"2025-04-13T11:32:31.414710Z","iopub.execute_input":"2025-04-13T11:32:31.415190Z","iopub.status.idle":"2025-04-13T11:32:31.544707Z","shell.execute_reply.started":"2025-04-13T11:32:31.415167Z","shell.execute_reply":"2025-04-13T11:32:31.544081Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":["### Prompt generation functions\n","Example prompts for testing"],"metadata":{"id":"xtohLZo936FU"}},{"cell_type":"markdown","source":["#### Dreaddit Prompt\n","Zero shot prompt based on stress definition used to label the Dreaddit dataset."],"metadata":{"id":"qeNdP6Mab6Bc"}},{"cell_type":"code","source":["import pandas as pd\n","# Messages can be classified to indicate stress in the speaker. The following classes are used:\n","\n","def create_dreaddit_prompt(bodies_df: pd.DataFrame) -> str:\n","  messagesStart = \\\n","  '''\n"," <|user|>\n"," Messages can be classified as follows:\n","\n"," '1' is the class that indicates a state of mental or emotional strain or tension resulting\n"," from adverse or demanding circumstances.\n","\n"," '0' is the class that indicates the speaker is not expressing a state of mental or emotional strain or tension resulting\n"," from adverse or demanding circumstances.\n","\n"," Output a single line of comma separated classes the {} messages beginning with the word \"Classifications\":  There should be {} classes in the line.\n"," Output a single line of comma separated probabilities for class '1' beginning with the word \"Probabilities\":  There should be {} probabilities in the line.\n","\n"," '''.format(len(bodies_df), len(bodies_df),len(bodies_df), len(bodies_df))\n","  # Loop through the DataFrame\n","  bodies_list = ''\n","  for i in range(0, len(bodies_df)):\n","    # print(\"add message to prompt: \", bodies_df.iloc[i].text)\n","    message = \"\\n\" + \"message: \" + \"'\" + bodies_df.iloc[i].text +\"'\\n\"\n","    bodies_list = bodies_list + message\n","\n","  messagesEnd = \\\n","  '''\n","  <|end|>\n","  <|assistant|>\n","  '''\n","\n","  messages = messagesStart + bodies_list + messagesEnd\n","\n","  return messages"],"metadata":{"id":"Vajm885v34c9","trusted":true,"execution":{"iopub.status.busy":"2025-04-13T11:32:31.545447Z","iopub.execute_input":"2025-04-13T11:32:31.545749Z","iopub.status.idle":"2025-04-13T11:32:31.575745Z","shell.execute_reply.started":"2025-04-13T11:32:31.545718Z","shell.execute_reply":"2025-04-13T11:32:31.574969Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":["#### Goode Prompt\n","Zero shot prompt based on William J. Goode's 1960 study, \"A Theory of Role Strain\""],"metadata":{"id":"D3Kz8S6gb6Bg"}},{"cell_type":"code","source":["import pandas as pd\n","def create_goode_prompt(bodies_df: pd.DataFrame) -> str:\n","  messagesStart = \\\n","  '''\n"," <|user|>\n"," Messages can be classified to indicate stress in the speaker. Stress is defined as:\n","\n","* Role Overload: The inability to meet the sheer quantity of demands due to a lack of time or resources.\n","* Role Conflict: Situations where the expectations of one role are incompatible with the expectations of another.\n","* Role Ambiguity: Uncertainty or lack of clarity about role expectations, which can heighten tension.\n","\n","'0' is the class that indicates the speaker is not expressing role overload or role conflict or role ambiguity\n","from adverse or demanding circumstances.\n","\n","'1' is the class that indicates the speaker is expressing role overload or role conflict or role ambiguity\n","from adverse or demanding circumstances.\n","\n","Provide only one class for each of the following {} messages. Output a single line of {} comma separated classes beginning with the word \"Classifications\":\n","Provide one probability for each of the following {} messages. Output a single line of {} comma separated probabilities beginning with the word \"Probabilities\":\n","\n"," '''.format(len(bodies_df), len(bodies_df),len(bodies_df), len(bodies_df))\n","  # Loop through the DataFrame\n","  bodies_list = ''\n","  for i in range(0, len(bodies_df)):\n","    # print(\"add message to prompt: \", bodies_df.iloc[i].text)\n","    message = \"\\n\" + \"message: \" + \"'\" + bodies_df.iloc[i].text +\"'\\n\"\n","    bodies_list = bodies_list + message\n","\n","  messagesEnd = \\\n","  '''\n","  <|end|>\n","  <|assistant|>\n","  '''\n","\n","  messages = messagesStart + bodies_list + messagesEnd\n","\n","  return messages"],"metadata":{"id":"aD92oPgYMyNw","trusted":true,"execution":{"iopub.status.busy":"2025-04-13T11:32:31.577672Z","iopub.execute_input":"2025-04-13T11:32:31.577867Z","iopub.status.idle":"2025-04-13T11:32:31.596238Z","shell.execute_reply.started":"2025-04-13T11:32:31.577850Z","shell.execute_reply":"2025-04-13T11:32:31.595468Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":["#### Lazarus Prompt\n","Zero shot prompt based on \"Stress, Appraisal, and Coping\" by Richard S. Lazarus and Susan Folkman,"],"metadata":{"id":"V9yrNLASb6Bi"}},{"cell_type":"code","source":["import pandas as pd\n","def create_lazarus_prompt(bodies_df: pd.DataFrame) -> str:\n","  messagesStart = \\\n","  '''\n"," <|user|>\n"," Messages can be classified to indicate stress in the speaker. The following classes are used:\n","\n","'1' is the class that indicates the speaker's appraisal of the demands of a situation exceed available resources and thus endangering well-being.\n","\n","'0' is the class that indicates the speaker's appraisal of the demands of a situation do not exceed available resources and thus do not endanger well-being.\n","\n"," Provide only one class for each of the following {} messages. Output a single line of {} comma separated classes beginning with the word \"Classifications\":\n"," Provide one probability for each of the following {} messages. Output a single line of {} comma separated probabilities beginning with the word \"Probabilities\":\n","\n"," '''.format(len(bodies_df), len(bodies_df),len(bodies_df), len(bodies_df))\n","  # Loop through the DataFrame\n","  bodies_list = ''\n","  for i in range(0, len(bodies_df)):\n","    # print(\"add message to prompt: \", bodies_df.iloc[i].text)\n","    message = \"\\n\" + \"message: \" + \"'\" + bodies_df.iloc[i].text +\"'\\n\"\n","    bodies_list = bodies_list + message\n","\n","  messagesEnd = \\\n","  '''\n","  <|end|>\n","  <|assistant|>\n","  '''\n","\n","  messages = messagesStart + bodies_list + messagesEnd\n","\n","  return messages"],"metadata":{"id":"Ror-hT-cM_38","trusted":true,"execution":{"iopub.status.busy":"2025-04-13T11:32:31.597438Z","iopub.execute_input":"2025-04-13T11:32:31.597666Z","iopub.status.idle":"2025-04-13T11:32:31.615953Z","shell.execute_reply.started":"2025-04-13T11:32:31.597636Z","shell.execute_reply":"2025-04-13T11:32:31.615318Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":["import pandas as pd\n","def create_examples_prompt(bodies_df: pd.DataFrame) -> str:\n","  messagesStart = \\\n","  '''\n"," <|user|>\n"," Messages can be classified to indicate stress in the speaker. The classes are \"1\" and \"0\" and are shown in the following examples:\n","\n"," class: \"1\" message : \"Why did I open my mouth I should’ve just said “I’m fine” ~ I don’t need help Or maybe I do\"\n","\n"," class: \"1\" message : \"I don’t know. Was this okay? Should I hate him? Or was it just something new? I really don’t know what to make of the situation.\"\n","\n"," class: \"1\" message : \"Idk Do I tell someone? Do I just quit? Do I talk to her about what she did? Please, any advice would be really really helpful to me!\"\n","\n"," class: \"0\" message: \"i faced up to myself. i completed probation. it's not the drugs i need. it's to leave my environment and everything i know; it's to get a fresh start. i'm only 22.\"\n","\n"," class: \"0\" message : \"So I'm between paychecks and I've managed to get of my act together to pay most of my bills by asking the church and through private donations.\"\n","\n"," class: \"1\" message : \"Every day I hope she messages me, calls me, or post on my Facebook. Any advice would mean the world to me. How to get over my ex!\"\n","\n"," class: \"1\" message : \"I can have it in front of me and still overthink and ask my self over and over. Any advice or opinions? Thanks. P.S. I don’t suffer a lot when I’m busy at work or with friends.\"\n","\n"," class: \"0\" message : \"One night, early, early into this, we were kind of flirting. He suggested we shower together. I was scared. Uncomfortable. Not sure.\"\n","\n"," class: \"0\" message : \"* Sleeping bag. * Solar-powered Lamps. * A raincoat. * Non-perishable food/MREs/trailmix. Anything else I should invest in?\"\n","\n"," class: \"0\" message : \"Maybe a couple more days will get me back to normal. Definitely quitting the alcohol. It's an obvious trigger.\"\n","\n"," Provide only one class for each of the following {} messages. Output a single line of {} comma separated classes beginning with the word \"Classifications\":\n"," Provide one probability for each of the following {} messages. Output a single line of {} comma separated probabilities beginning with the word \"Probabilities\":\n","\n"," '''.format(len(bodies_df), len(bodies_df),len(bodies_df), len(bodies_df))\n","  # Loop through the DataFrame\n","  bodies_list = ''\n","  for i in range(0, len(bodies_df)):\n","    # print(\"add message to prompt: \", bodies_df.iloc[i].text)\n","    message = \"\\n\" + \"message: \" + \"'\" + bodies_df.iloc[i].text +\"'\\n\"\n","    bodies_list = bodies_list + message\n","\n","  messagesEnd = \\\n","  '''\n","  <|end|>\n","  <|assistant|>\n","  '''\n","\n","  messages = messagesStart + bodies_list + messagesEnd\n","\n","  return messages"],"metadata":{"id":"PyFlGcKEb6Bk","trusted":true,"execution":{"iopub.status.busy":"2025-04-13T11:32:31.616817Z","iopub.execute_input":"2025-04-13T11:32:31.617074Z","iopub.status.idle":"2025-04-13T11:32:31.635136Z","shell.execute_reply.started":"2025-04-13T11:32:31.617043Z","shell.execute_reply":"2025-04-13T11:32:31.634325Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":["### Load messages, dropping nulls and sorting on date created.\n"],"metadata":{"id":"7ec5EzcFC__S"}},{"cell_type":"code","source":["# URL of the raw CSV file on GitHub\n","csv_url = \"https://raw.githubusercontent.com/SocialHealthAI/SDOH-Models/refs/heads/main/LLM%20Classification/dreaddit-test.csv\"\n","\n","# Load the CSV file into a DataFrame\n","dreadit_df = pd.read_csv(csv_url)\n","dreadit_df = dreadit_df.head(test_count)         # limit the test data\n","split_index = len(dreadit_df) // 2\n","dreadit_d = dreadit_df.iloc[split_index:]\n","\n","dreadit_text_df = dreadit_df[['text']]\n","\n","# Display the first few rows of the DataFrame\n","print(dreadit_df.head())\n"],"metadata":{"id":"0VIXwvlosv-7","trusted":true,"execution":{"iopub.status.busy":"2025-04-13T11:32:31.636066Z","iopub.execute_input":"2025-04-13T11:32:31.636344Z","iopub.status.idle":"2025-04-13T11:32:32.041224Z","shell.execute_reply.started":"2025-04-13T11:32:31.636315Z","shell.execute_reply":"2025-04-13T11:32:32.040258Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":["### Load Model\n"],"metadata":{"id":"CpkeSwtErfsf"}},{"cell_type":"code","source":["# Load 4-bit quantized model\n","model = AutoModelForCausalLM.from_pretrained(model_name,\n","                                                load_in_4bit=True,  # Activates 8-bit quantization\n","                                                device_map=\"auto\"   # Automatically assigns the model to an available GPU\n","                                            )"],"metadata":{"id":"BkMGiEeWRYS3","trusted":true,"execution":{"iopub.status.busy":"2025-04-13T11:32:32.042154Z","iopub.execute_input":"2025-04-13T11:32:32.042480Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":["### Generate output\n","\n","Run generate in batches so that prompts are not too large.  rows_per_seat determines the number of messages to score in each prompt. The number of messages to score are set by starting_row and ending_row.  To help generate deterministic output the folowwing are set:\n","* set_seed(42)\n","* temperature=0.0,\n","* do_sample=False,\n"],"metadata":{"id":"64dLIo3ab6Bn"}},{"cell_type":"code","source":["import torch\n","import time\n","\n","# Define the starting row index\n","starting_row = 0\n","# Define ending row index\n","#ending_row =  len(last_week_df)\n","ending_row =  test_count - 1\n","# Load the tokenizer\n","tokenizer = AutoTokenizer.from_pretrained(model_name)\n","# Set a seed for reproducibility\n","set_seed(42)\n","# separate batches of generated text\n","generated_texts = []\n","\n","# check starting row\n","if starting_row < 0 or starting_row >= len(dreadit_text_df):\n","    print(\"Invalid starting row index. Input data has length: \" + str(len(dreadit_text_df)))\n","    sys.exit(1)\n","\n","# check ending row\n","if ending_row < starting_row or ending_row >= len(dreadit_text_df):\n","    print(\"Invalid ending row index. Input data has length: \" + str(len(dreadit_text_df)))\n","    sys.exit(1)\n","\n","# acceleration support for input data\n","device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","#model.to(device)\n","\n","# Loop through the DataFrame in sets of 5 rows\n","start_time = time.time()  # Record the start time\n","for i in range(starting_row, ending_row, rows_per_set):\n","\n","  # Set up prompt defintion and tokenize\n","  messages = globals()[prompt_function](dreadit_text_df.iloc[i:i + rows_per_set])\n","  input_ids = tokenizer.encode(messages, return_tensors='pt')\n","  # acceleration support  This is not necessary if model is loaded with bitsandbytes support as it assigned to correct device\n","  input_ids = input_ids.to(device)\n","\n","  output = model.generate(\n","        input_ids,\n","        #max_length=1200,\n","        max_new_tokens=200,\n","        temperature=0.0,\n","        top_k=1,\n","        top_p=0.0,\n","        do_sample=False,  # Ensure deterministic output\n","        pad_token_id=tokenizer.eos_token_id\n","  )\n","\n","  # Decode and print the output\n","  generated_texts.append(tokenizer.decode(output[0], skip_special_tokens=True))\n","\n","# Calculate and print the elapsed time\n","elapsed_time = time.time() - start_time\n","print(f\"Time required by the function call: {elapsed_time:.4f} seconds\")\n"],"metadata":{"id":"vl8AuTIiJo_Q","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":["print(*generated_texts, sep = \"\\n\")"],"metadata":{"id":"y3WCxXYMa54j","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":["### Parse output to find Classifications and Probabilities\n","Look for \"Classifications:\" and then find numbers in the same in each batch of inferences and append to a dataframe of scores.\n","Look for \"Probabilities:\" and then find numbers in the same in each batch of inferences and append to a dataframe of probabilities.\n","Produce output_df with scores. probabilities."],"metadata":{"id":"6Rc05G3WoHwL"}},{"cell_type":"code","source":["import re\n","output_score_df = pd.DataFrame(columns=['score'])\n","output_probability_df = pd.DataFrame(columns=['probability'])\n","\n","for batch in generated_texts:\n","  # Split the text into lines\n","  lines = batch.split('\\n')\n","\n","  # Count the messages in the batch\n","  message_count = 0\n","  for i, line in enumerate(lines):\n","    if \"message: \" in line:\n","      message_count += 1\n","\n","  # Find the scores and predictions in the batch, making sure we match the number of messages.  The\n","  # transformer sometimes misses a message (1 in 2500).  We append neutral scores and .5 probability if\n","  # needed.\n","\n","  for i, line in enumerate(lines):\n","\n","    if \"Classifications:\" in line:\n","      numbers = re.findall(r'\\d+', lines[i])\n","      if len(numbers) == 0:\n","        print(\"Warning, no inferences found\")\n","      # Convert the extracted strings to integers\n","      numbers = [int(num) for num in numbers]\n","      print(line, numbers)\n","      while len(numbers) < message_count:\n","        numbers.append(0)\n","        print(\"Warning, score 0 appended as score number in: \", numbers, \" is less than: \", message_count)\n","      # Create a DataFrame from the numbers list\n","      batch_df = pd.DataFrame(numbers, columns=['score'])\n","      # Append the new numbers to the output DataFrame\n","      output_score_df = pd.concat([output_score_df, batch_df], ignore_index=True)\n","      break\n","\n","  for i, line in enumerate(lines):\n","    if \"Probabilities:\" in line:\n","      numbers = re.findall(r'\\d+\\.\\d+|\\d+', line)\n","      if len(numbers) == 0:\n","        print(\"Warning, no probabilities found\")\n","      # Convert the extracted strings to float\n","      numbers = [float(num) for num in numbers]\n","      print(line, numbers)\n","      while len(numbers) < message_count:\n","        numbers.append(0.5)\n","        print(\"Warning, probability .5 appended in: \", numbers, \" is less than: \", message_count)\n","      #print(numbers)\n","      # Create a DataFrame from the numbers list\n","      batch_df = pd.DataFrame(numbers, columns=['probability'])\n","      # Append the new numbers to the output DataFrame\n","      output_probability_df = pd.concat([output_probability_df, batch_df], ignore_index=True)\n","      break\n","\n","output_df = pd.concat([output_score_df, output_probability_df], axis=1)"],"metadata":{"id":"W8qzGCIjcNSj","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":["output_df"],"metadata":{"id":"V0EgbXqx7Xfi"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Use ROC to determine best threshold for class 1"],"metadata":{"id":"Ps8ytIZSDXet"}},{"cell_type":"code","source":["from sklearn.metrics import f1_score, roc_auc_score, precision_recall_curve\n","import numpy as np\n","\n","# Get true labels and predicted probabilities\n","y_true = dreadit_df['label'].values\n","y_probs = output_df['probability'].values\n","\n","# Search for best threshold by maximizing F1-score\n","thresholds = np.arange(0.0, 1.01, 0.01)\n","f1_scores = [f1_score(y_true, y_probs > t) for t in thresholds]\n","best_threshold = thresholds[np.argmax(f1_scores)]\n","\n","print(f\"Best threshold based on F1-score: {best_threshold:.2f}\")\n"],"metadata":{"id":"-RfcFDeEDcxf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Classification Report\n","Classification report based on target labels provided in Dreadit dataset."],"metadata":{"id":"We11-GnWa9MC"}},{"cell_type":"code","source":["from sklearn.metrics import classification_report\n","\n","# Convert probabilities to labels based on best threshold\n","output_df['y_pred'] = (output_df['probability'] >= best_threshold).astype(int)\n","\n","# Print classification report\n","print(classification_report(y_true, output_df['y_pred']))\n"],"metadata":{"id":"5OoEUmIPcKHk","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","from sklearn.metrics import roc_curve, auc\n","\n","# Convert labels to NumPy array if not already\n","true_labels = dreadit_df['label'].to_numpy()\n","positive_probs = output_df['probability'].to_numpy()\n","\n","# If binary classification, extract probability of positive class (class 1)\n","#if test_probs.shape[1] == 2:\n","#    positive_probs = test_probs[:, 1]  # Probability of class 1\n","#else:\n","#    raise ValueError(\"ROC is typically used for binary classification. For multi-class, consider One-vs-Rest.\")\n","\n","# Compute ROC curve\n","fpr, tpr, _ = roc_curve(true_labels, positive_probs)\n","roc_auc = auc(fpr, tpr)\n","\n","# Plot\n","plt.figure(figsize=(8, 6))\n","plt.plot(fpr, tpr, color='blue', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')\n","plt.plot([0, 1], [0, 1], color='grey', linestyle='--')  # Diagonal line for random chance\n","plt.xlim([0.0, 1.0])\n","plt.ylim([0.0, 1.05])\n","plt.xlabel('False Positive Rate')\n","plt.ylabel('True Positive Rate')\n","plt.title('Receiver Operating Characteristic (ROC) Curve')\n","plt.legend(loc=\"lower right\")\n","plt.show()"],"metadata":{"trusted":true,"id":"Fj4f16W-kjT9"},"outputs":[],"execution_count":null},{"cell_type":"code","source":["output_probability_df"],"metadata":{"trusted":true,"jupyter":{"source_hidden":true},"id":"I0N7z6IKkjT9"},"outputs":[],"execution_count":null}]}