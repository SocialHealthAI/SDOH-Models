{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU","kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"nLJkX47Bg-K4","cell_type":"markdown","source":"## Fine tune Phi-3 and Llama for sequence classification\n\nFine tune to classify stress or no stress using messages from Dreaddit: A Reddit Dataset for Stress Analysis in Social Media.\nSee: https://aclanthology.org/D19-6213\n\nCommonly updated parameters are in the Parameter block below.\n\n**test_count:** The number of messages to use in generating prompts.\n\n**model_name** The model ID downloaded from Hugging Face.\n\n**access_token** The Hugging Face access token.\n\nNote, to work with batched input had to set padding=True when tokenizing input. Training loop handles the padded tokens correctly by masking them during the loss computation: attention_mask=ds_tokenized[\"train\"][\"attention_mask\"]\n\nTraining data was reduced to 1200 to not exhaust GPU memory on Kaggle.","metadata":{"id":"nLJkX47Bg-K4"}},{"id":"8ec99e5d-039e-421c-bc6e-eed3a2e78a83","cell_type":"markdown","source":"#### Parameters","metadata":{}},{"id":"31c2bf66-fe82-4bc4-a031-f438079af42d","cell_type":"code","source":"test_count = 1200\nmodel_name  = \"microsoft/Phi-3-medium-4K-instruct\"\n#model_name =  \"meta-llama/Llama-2-7b-hf\"\n#model_name = \"deepseek-ai/DeepSeek-R1-Distill-Qwen-7B\"\naccess_token = 'access token here'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T11:48:09.750498Z","iopub.execute_input":"2025-04-20T11:48:09.750725Z","iopub.status.idle":"2025-04-20T11:48:09.754790Z","shell.execute_reply.started":"2025-04-20T11:48:09.750697Z","shell.execute_reply":"2025-04-20T11:48:09.753651Z"}},"outputs":[],"execution_count":1},{"id":"be5d91ed-7501-4d8c-8d4a-56cd4cf6e24a","cell_type":"markdown","source":"","metadata":{"id":"be5d91ed-7501-4d8c-8d4a-56cd4cf6e24a"}},{"id":"K0ESnwEl0fx1","cell_type":"code","source":"!pip install transformers\n!pip install torch # torch\n!pip install peft # necessary for finetuning of the large model via LoRA approach\n!pip install bitsandbytes # necessary for quantiziation\n!pip install evaluate # extension of the transformers library\n!pip install datasets # extension of the transformers library\n!pip install accelerate","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"K0ESnwEl0fx1","outputId":"569dcd15-1afd-4e29-fa90-87d53622b2f0","trusted":true,"execution":{"iopub.status.busy":"2025-04-20T11:48:09.755730Z","iopub.execute_input":"2025-04-20T11:48:09.756066Z","iopub.status.idle":"2025-04-20T11:48:37.315725Z","shell.execute_reply.started":"2025-04-20T11:48:09.756032Z","shell.execute_reply":"2025-04-20T11:48:37.314571Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.47.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.17.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.29.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.0)\nRequirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.67.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.12.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2025.1.31)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->transformers) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.17.0)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.12.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\nRequirement already satisfied: peft in /usr/local/lib/python3.10/dist-packages (0.14.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from peft) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from peft) (24.2)\nRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from peft) (5.9.5)\nRequirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from peft) (6.0.2)\nRequirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from peft) (2.5.1+cu121)\nRequirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from peft) (4.47.0)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from peft) (4.67.1)\nRequirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from peft) (1.2.1)\nRequirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from peft) (0.4.5)\nRequirement already satisfied: huggingface-hub>=0.25.0 in /usr/local/lib/python3.10/dist-packages (from peft) (0.29.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.0->peft) (3.17.0)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.0->peft) (2024.12.0)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.0->peft) (2.32.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.0->peft) (4.12.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->peft) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->peft) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->peft) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->peft) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->peft) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->peft) (2.4.1)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.1.4)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.13.0->peft) (1.3.0)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->peft) (2024.11.6)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers->peft) (0.21.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13.0->peft) (3.0.2)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->peft) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->peft) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->peft) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.17->peft) (2024.2.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.25.0->peft) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.25.0->peft) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.25.0->peft) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.25.0->peft) (2025.1.31)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.17->peft) (2024.2.0)\nCollecting bitsandbytes\n  Downloading bitsandbytes-0.45.5-py3-none-manylinux_2_24_x86_64.whl.metadata (5.0 kB)\nRequirement already satisfied: torch<3,>=2.0 in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (2.5.1+cu121)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (1.26.4)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->bitsandbytes) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->bitsandbytes) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->bitsandbytes) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->bitsandbytes) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->bitsandbytes) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->bitsandbytes) (2.4.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.17.0)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch<3,>=2.0->bitsandbytes) (4.12.2)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.1.4)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch<3,>=2.0->bitsandbytes) (2024.12.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch<3,>=2.0->bitsandbytes) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch<3,>=2.0->bitsandbytes) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch<3,>=2.0->bitsandbytes) (3.0.2)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->bitsandbytes) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->bitsandbytes) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->bitsandbytes) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.17->bitsandbytes) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.17->bitsandbytes) (2024.2.0)\nDownloading bitsandbytes-0.45.5-py3-none-manylinux_2_24_x86_64.whl (76.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.1/76.1 MB\u001b[0m \u001b[31m23.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: bitsandbytes\nSuccessfully installed bitsandbytes-0.45.5\nCollecting evaluate\n  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\nRequirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.3.1)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.26.4)\nRequirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.2.3)\nRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.32.3)\nRequirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from evaluate) (4.67.1)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.5.0)\nRequirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.70.16)\nRequirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.12.0)\nRequirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.29.0)\nRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from evaluate) (24.2)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.17.0)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (19.0.1)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.11.12)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->evaluate) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->evaluate) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->evaluate) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->evaluate) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->evaluate) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->evaluate) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2025.1.31)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2025.1)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2025.1)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.4.6)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.2)\nRequirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (5.0.1)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (25.1.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.1.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (0.2.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.18.3)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->evaluate) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->evaluate) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->evaluate) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.17->evaluate) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.17->evaluate) (2024.2.0)\nDownloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: evaluate\nSuccessfully installed evaluate-0.4.3\nRequirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.3.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.17.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (19.0.1)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.3)\nRequirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\nRequirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.67.1)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\nRequirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.12.0)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.12)\nRequirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.29.0)\nRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.6)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.2)\nRequirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (5.0.1)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (25.1.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.18.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.12.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->datasets) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->datasets) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->datasets) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->datasets) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->datasets) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->datasets) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2025.1)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2025.1)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->datasets) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->datasets) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->datasets) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.17->datasets) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.17->datasets) (2024.2.0)\nRequirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (1.2.1)\nRequirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (24.2)\nRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\nRequirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.2)\nRequirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.5.1+cu121)\nRequirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.29.0)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.5)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (3.17.0)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (2024.12.0)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (2.32.3)\nRequirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (4.67.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (4.12.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy<3.0.0,>=1.17->accelerate) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy<3.0.0,>=1.17->accelerate) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy<3.0.0,>=1.17->accelerate) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy<3.0.0,>=1.17->accelerate) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy<3.0.0,>=1.17->accelerate) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy<3.0.0,>=1.17->accelerate) (2.4.1)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.4)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.10.0->accelerate) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (3.0.2)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<3.0.0,>=1.17->accelerate) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<3.0.0,>=1.17->accelerate) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy<3.0.0,>=1.17->accelerate) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy<3.0.0,>=1.17->accelerate) (2024.2.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2025.1.31)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy<3.0.0,>=1.17->accelerate) (2024.2.0)\n","output_type":"stream"}],"execution_count":2},{"id":"92h2kCYH0q33","cell_type":"code","source":"import torch\nimport pandas as pd\nfrom datasets import Dataset, load_dataset, DatasetDict\nfrom peft import LoraConfig, PeftModel, prepare_model_for_kbit_training, get_peft_model\nfrom transformers import (\n    AutoTokenizer,\n    BitsAndBytesConfig,\n    TrainingArguments,\n    AutoModelForSequenceClassification,\n    TrainingArguments,\n    Trainer,\n    EarlyStoppingCallback,\n    DataCollatorWithPadding,\n    TextClassificationPipeline)\nfrom sklearn.model_selection import train_test_split\n\nimport bitsandbytes as bnb\n\nimport evaluate\nimport numpy as np\nimport time\nimport random","metadata":{"id":"92h2kCYH0q33","trusted":true,"execution":{"iopub.status.busy":"2025-04-20T11:48:37.317110Z","iopub.execute_input":"2025-04-20T11:48:37.317500Z","iopub.status.idle":"2025-04-20T11:49:00.558535Z","shell.execute_reply.started":"2025-04-20T11:48:37.317470Z","shell.execute_reply":"2025-04-20T11:49:00.557663Z"}},"outputs":[],"execution_count":3},{"id":"lgeTaKIxRcMr","cell_type":"code","source":"# Set start time for training\nstart_time = time.time()","metadata":{"id":"lgeTaKIxRcMr","trusted":true,"execution":{"iopub.status.busy":"2025-04-20T11:49:00.559560Z","iopub.execute_input":"2025-04-20T11:49:00.560292Z","iopub.status.idle":"2025-04-20T11:49:00.563859Z","shell.execute_reply.started":"2025-04-20T11:49:00.560254Z","shell.execute_reply":"2025-04-20T11:49:00.562925Z"}},"outputs":[],"execution_count":4},{"id":"chHcNT6K06kc","cell_type":"markdown","source":"### Logon to HuggingFace","metadata":{"id":"chHcNT6K06kc"}},{"id":"ahEgRnlB0-RO","cell_type":"code","source":"### the safer way\n#from huggingface_hub import notebook_login\n#notebook_login()\n\n### alternative\nfrom huggingface_hub import login\nlogin(access_token) ","metadata":{"id":"ahEgRnlB0-RO","trusted":true,"execution":{"iopub.status.busy":"2025-04-20T11:49:00.564837Z","iopub.execute_input":"2025-04-20T11:49:00.565186Z","iopub.status.idle":"2025-04-20T11:49:00.722183Z","shell.execute_reply.started":"2025-04-20T11:49:00.565106Z","shell.execute_reply":"2025-04-20T11:49:00.721436Z"}},"outputs":[],"execution_count":5},{"id":"7ec5EzcFC__S","cell_type":"markdown","source":"### Load messages, dropping nulls.\n","metadata":{"id":"7ec5EzcFC__S"}},{"id":"0VIXwvlosv-7","cell_type":"code","source":"# URL of the raw CSV file on GitHub\ncsv_url = \"https://raw.githubusercontent.com/SocialHealthAI/SDOH-Models/refs/heads/main/LLM%20Classification/dreaddit-train.csv\"\n\n# Load the CSV file into a DataFrame\ntrain_df = pd.read_csv(csv_url)\ntrain_df = train_df.head(test_count)             \n#dreadit_text_df = dreadit_df[['text']]\n\n# URL of the raw CSV file on GitHub\ncsv_url = \"https://raw.githubusercontent.com/SocialHealthAI/SDOH-Models/refs/heads/main/LLM%20Classification/dreaddit-test.csv\"\n\n# Load the CSV file into a DataFrame\ntest_df = pd.read_csv(csv_url)\ntest_df = test_df.head(400)             \n#dreadit_text_df = dreadit_df[['text']]\n\n# drop null text\ntrain_df.dropna(subset=['text'], inplace=True)\ntest_df.dropna(subset=['text'], inplace=True)\n","metadata":{"id":"0VIXwvlosv-7","trusted":true,"execution":{"iopub.status.busy":"2025-04-20T11:49:00.724867Z","iopub.execute_input":"2025-04-20T11:49:00.725084Z","iopub.status.idle":"2025-04-20T11:49:01.526560Z","shell.execute_reply.started":"2025-04-20T11:49:00.725066Z","shell.execute_reply":"2025-04-20T11:49:01.525589Z"}},"outputs":[],"execution_count":6},{"id":"tFfIldfMUfvZ","cell_type":"code","source":"label_names = ['0', '1']","metadata":{"id":"tFfIldfMUfvZ","trusted":true,"execution":{"iopub.status.busy":"2025-04-20T11:49:01.528127Z","iopub.execute_input":"2025-04-20T11:49:01.528415Z","iopub.status.idle":"2025-04-20T11:49:01.532317Z","shell.execute_reply.started":"2025-04-20T11:49:01.528392Z","shell.execute_reply":"2025-04-20T11:49:01.531380Z"}},"outputs":[],"execution_count":7},{"id":"KcFt8-MIcXs2","cell_type":"markdown","source":"### Split test data into test and validation data","metadata":{"id":"KcFt8-MIcXs2"}},{"id":"NhXjYIxkcbS-","cell_type":"code","source":"# Calculate the split index\nsplit_index = len(test_df) // 2\n\n# Split the DataFrame\nvalidation_df = test_df.iloc[:split_index]\ntest_df = test_df.iloc[split_index:]\n","metadata":{"id":"NhXjYIxkcbS-","trusted":true,"execution":{"iopub.status.busy":"2025-04-20T11:49:01.533214Z","iopub.execute_input":"2025-04-20T11:49:01.533624Z","iopub.status.idle":"2025-04-20T11:49:01.546000Z","shell.execute_reply.started":"2025-04-20T11:49:01.533542Z","shell.execute_reply":"2025-04-20T11:49:01.545319Z"}},"outputs":[],"execution_count":8},{"id":"ZDGYKunVhlQx","cell_type":"markdown","source":"### Create DatasetDict","metadata":{"id":"ZDGYKunVhlQx"}},{"id":"RwHeqnwLaUJd","cell_type":"code","source":"train_body = train_df['text'].values.tolist()\ntrain_label = np.array(train_df['label'].values.tolist())\n\nval_body = validation_df['text'].values.tolist()\nval_label = np.array(validation_df['label'].values.tolist())\n\ntest_body = test_df['text'].values.tolist()\ntest_label = np.array(test_df['label'].values.tolist())\n\n# create hf dataset\nds = DatasetDict({\n    'train': Dataset.from_dict({'body': train_body, 'label': train_label}),\n    'val': Dataset.from_dict({'body': val_body, 'label': val_label}),\n    'test': Dataset.from_dict({'body': test_body, 'label': test_label})\n})","metadata":{"id":"RwHeqnwLaUJd","trusted":true,"execution":{"iopub.status.busy":"2025-04-20T11:49:01.546699Z","iopub.execute_input":"2025-04-20T11:49:01.546885Z","iopub.status.idle":"2025-04-20T11:49:01.580941Z","shell.execute_reply.started":"2025-04-20T11:49:01.546868Z","shell.execute_reply":"2025-04-20T11:49:01.580306Z"}},"outputs":[],"execution_count":9},{"id":"JHjKw0R0JwyJ","cell_type":"code","source":"ds['train'][0]","metadata":{"id":"JHjKw0R0JwyJ","trusted":true,"execution":{"iopub.status.busy":"2025-04-20T11:49:01.581653Z","iopub.execute_input":"2025-04-20T11:49:01.581857Z","iopub.status.idle":"2025-04-20T11:49:01.590220Z","shell.execute_reply.started":"2025-04-20T11:49:01.581840Z","shell.execute_reply":"2025-04-20T11:49:01.589641Z"}},"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"{'body': 'He said he had not felt that way before, suggeted I go rest and so ..TRIGGER AHEAD IF YOUI\\'RE A HYPOCONDRIAC LIKE ME: i decide to look up \"feelings of doom\" in hopes of maybe getting sucked into some rabbit hole of ludicrous conspiracy, a stupid \"are you psychic\" test or new age b.s., something I could even laugh at down the road. No, I ended up reading that this sense of doom can be indicative of various health ailments; one of which I am prone to.. So on top of my \"doom\" to my gloom..I am now f\\'n worried about my heart. I do happen to have a physical in 48 hours.',\n 'label': 1}"},"metadata":{}}],"execution_count":10},{"id":"XrryyoPr3daK","cell_type":"markdown","source":"### Tokenization and Quantization\nLoad tokenizer.\n\nDefine tokenizer function with truncation=True so sequences are truncated to a specific length (often used for training).  \n\nUse the map function from the Datasets library to apply the preprocess_function to IMDb dataset in batches for efficiency. This creates a new dataset named tokenized_imdb with additional columns:\n\n* input_ids: Numerical representation of the text using tokenizer vocabulary.\n* attention_mask: Mask to indicate valid elements in padded sequences.","metadata":{"id":"XrryyoPr3daK"}},{"id":"aMYV7Y4z3k00","cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(model_name)\ntokenizer.pad_token = tokenizer.eos_token                                         # added\nprint(f' Vocab size of the model {model_name}: {len(tokenizer.get_vocab())}')\n#Vocab size of the model google/gemma-2b-it: 256000\n\ndef preprocess_function(examples):\n    return tokenizer(examples[\"body\"], truncation=True, padding=True)\n\nds_tokenized = ds.map(preprocess_function, batched=True)","metadata":{"id":"aMYV7Y4z3k00","trusted":true,"execution":{"iopub.status.busy":"2025-04-20T11:49:01.590987Z","iopub.execute_input":"2025-04-20T11:49:01.591210Z","iopub.status.idle":"2025-04-20T11:49:04.451209Z","shell.execute_reply.started":"2025-04-20T11:49:01.591191Z","shell.execute_reply":"2025-04-20T11:49:04.450348Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/3.15k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e448b47f4c4b4bb69b2db819742236eb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eb819851da7a4a82893ac915e439a7d2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6a82f776d3034da692bf72c97a685148"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"added_tokens.json:   0%|          | 0.00/293 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1a65189fd38845aa9b5d9a5e78f90d4a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/568 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7b43cf66a7764b7683b3dbea89295a85"}},"metadata":{}},{"name":"stdout","text":" Vocab size of the model microsoft/Phi-3-medium-4K-instruct: 32011\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1200 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7d05465e4aae4e069f76f2526726a13c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/200 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9f03dce4730e48989a4ec6188337f952"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/200 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8ecd98ac027040a28e0580fd81af6c90"}},"metadata":{}}],"execution_count":11},{"id":"2X7ap4pi6QbZ","cell_type":"markdown","source":"### Label mapping\ncreate dictionaries to map labels (text) to numerical IDs and vice versa:","metadata":{"id":"2X7ap4pi6QbZ"}},{"id":"G0VgRqv-6axn","cell_type":"code","source":"id2label = {0: \"Not Stressed\", 1: \"Stressed\"}\nlabel2id = {\"Not Stressed\": 0, \"Stressed\": 1}","metadata":{"id":"G0VgRqv-6axn","trusted":true,"execution":{"iopub.status.busy":"2025-04-20T11:49:04.452279Z","iopub.execute_input":"2025-04-20T11:49:04.452636Z","iopub.status.idle":"2025-04-20T11:49:04.456792Z","shell.execute_reply.started":"2025-04-20T11:49:04.452592Z","shell.execute_reply":"2025-04-20T11:49:04.455798Z"}},"outputs":[],"execution_count":12},{"id":"PwpPphTk6l8J","cell_type":"markdown","source":"### Data Collator\nThe DataCollatorWithPadding class from Transformers helps prepare batches of data for training. It handles padding sequences to a common length and creates attention masks. We can simply instantiate it with the tokenizer","metadata":{"id":"PwpPphTk6l8J"}},{"id":"uyHPHQej6vlR","cell_type":"code","source":"data_collator = DataCollatorWithPadding(tokenizer=tokenizer)","metadata":{"id":"uyHPHQej6vlR","trusted":true,"execution":{"iopub.status.busy":"2025-04-20T11:49:04.457547Z","iopub.execute_input":"2025-04-20T11:49:04.457747Z","iopub.status.idle":"2025-04-20T11:49:04.475984Z","shell.execute_reply.started":"2025-04-20T11:49:04.457729Z","shell.execute_reply":"2025-04-20T11:49:04.475064Z"}},"outputs":[],"execution_count":13},{"id":"89vpgDA9684o","cell_type":"markdown","source":"### Evaluation Metrics\nTo assess the performance of our fine-tuned GEMMA-2b model use the evaluate library. This library provides convenient functions for calculating various evaluation metrics commonly used in classification tasks.\n\nDefine a function compute_metrics that takes the model's predictions and ground-truth labels as input and calculates several metrics","metadata":{"id":"89vpgDA9684o"}},{"id":"AXy0CTzx7RNY","cell_type":"code","source":"from sklearn.metrics import accuracy_score, f1_score\ndef compute_metrics(eval_pred):\n    logits, labels = eval_pred\n    predictions = np.argmax(logits, axis=-1)  # Convert logits to class predictions\n    accuracy = accuracy_score(labels, predictions)\n    f1 = f1_score(labels, predictions, average=\"weighted\")\n    return {\"accuracy\": accuracy, \"f1\": f1}\n","metadata":{"id":"AXy0CTzx7RNY","trusted":true,"execution":{"iopub.status.busy":"2025-04-20T11:49:04.476788Z","iopub.execute_input":"2025-04-20T11:49:04.477020Z","iopub.status.idle":"2025-04-20T11:49:04.485913Z","shell.execute_reply.started":"2025-04-20T11:49:04.476990Z","shell.execute_reply":"2025-04-20T11:49:04.484999Z"}},"outputs":[],"execution_count":14},{"id":"JE8w1YGJ7gdH","cell_type":"markdown","source":"#Quantization Configuration\nTransformers library provides the BitsAndBytesConfig class for defining quantization parameters.","metadata":{"id":"JE8w1YGJ7gdH"}},{"id":"wRgPQaBB7rkf","cell_type":"code","source":"bnb_config = BitsAndBytesConfig(\n    load_in_4bit=True,  # Enables 4-bit quantization\n    bnb_4bit_use_double_quant=True,  # Use double quantization for potentially higher accuracy (optional)\n    bnb_4bit_quant_type=\"nf4\",  # Quantization type (specifics depend on hardware and library)\n    bnb_4bit_compute_dtype=torch.bfloat16  # Compute dtype for improved efficiency (optional)\n)","metadata":{"id":"wRgPQaBB7rkf","trusted":true,"execution":{"iopub.status.busy":"2025-04-20T11:49:04.486920Z","iopub.execute_input":"2025-04-20T11:49:04.487245Z","iopub.status.idle":"2025-04-20T11:49:04.501415Z","shell.execute_reply.started":"2025-04-20T11:49:04.487198Z","shell.execute_reply":"2025-04-20T11:49:04.500741Z"}},"outputs":[],"execution_count":15},{"id":"_FmS9ss377_4","cell_type":"markdown","source":"### Load model in 4-bit\n","metadata":{"id":"_FmS9ss377_4"}},{"id":"8Jox6MOY7_pQ","cell_type":"code","source":"model = AutoModelForSequenceClassification.from_pretrained(\n    model_name,\n    problem_type=\"single_label_classification\",                                # added, why? its binary\n    num_labels=2,  # Number of output labels\n    id2label=id2label,\n    label2id=label2id,\n    quantization_config=bnb_config,  # configuration for quantization\n    device_map={\"\": 0}  # Optional dictionary specifying device mapping (single GPU with index 0 here)\n)","metadata":{"id":"8Jox6MOY7_pQ","trusted":true,"execution":{"iopub.status.busy":"2025-04-20T11:49:04.502307Z","iopub.execute_input":"2025-04-20T11:49:04.502542Z","iopub.status.idle":"2025-04-20T11:53:23.798969Z","shell.execute_reply.started":"2025-04-20T11:49:04.502521Z","shell.execute_reply":"2025-04-20T11:53:23.798306Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/934 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3bff46a15e0f4d59a4884e7380fa4d3d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/20.4k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"722c25ab74c644c58e932d8a693b31ad"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/6 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8f6c0c7ab0a14772ac6c03aaa4a9819f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00006.safetensors:   0%|          | 0.00/4.92G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b44f6b9227eb42b9a803f2114e39acea"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00006.safetensors:   0%|          | 0.00/4.95G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"be3b8c273a60422a97d7bc7bf887a1fe"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00003-of-00006.safetensors:   0%|          | 0.00/4.90G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6f0cdc406ad54a0fa7c3532ae31d53b4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00004-of-00006.safetensors:   0%|          | 0.00/4.77G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cf688b99b80948f388ad9b489e974811"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00005-of-00006.safetensors:   0%|          | 0.00/4.77G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0ccc2ac90009417aa91d9f9ba875bd89"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00006-of-00006.safetensors:   0%|          | 0.00/3.61G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"86b2eee138814fd3bd0aad07e0f64587"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bc69c6bbb67d4e14a8285d1dc0e8df3d"}},"metadata":{}},{"name":"stderr","text":"Some weights of Phi3ForSequenceClassification were not initialized from the model checkpoint at microsoft/Phi-3-medium-4K-instruct and are newly initialized: ['score.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":16},{"id":"GkR5c4cq_Bma","cell_type":"markdown","source":"### Gradient checkpointing\nMemory optimization technique that can be helpful for large models.","metadata":{"id":"GkR5c4cq_Bma"}},{"id":"NGsyPEX0--j-","cell_type":"code","source":"model.gradient_checkpointing_enable()","metadata":{"id":"NGsyPEX0--j-","trusted":true,"execution":{"iopub.status.busy":"2025-04-20T11:53:23.799761Z","iopub.execute_input":"2025-04-20T11:53:23.799981Z","iopub.status.idle":"2025-04-20T11:53:23.805018Z","shell.execute_reply.started":"2025-04-20T11:53:23.799953Z","shell.execute_reply":"2025-04-20T11:53:23.804302Z"}},"outputs":[],"execution_count":17},{"id":"7JJyTxvY_YBl","cell_type":"markdown","source":"### prepare model for quantization","metadata":{"id":"7JJyTxvY_YBl"}},{"id":"HIgsLeW9_b3d","cell_type":"code","source":"model = prepare_model_for_kbit_training(model)","metadata":{"id":"HIgsLeW9_b3d","trusted":true,"execution":{"iopub.status.busy":"2025-04-20T11:53:23.805945Z","iopub.execute_input":"2025-04-20T11:53:23.806252Z","iopub.status.idle":"2025-04-20T11:53:23.849877Z","shell.execute_reply.started":"2025-04-20T11:53:23.806202Z","shell.execute_reply":"2025-04-20T11:53:23.849295Z"}},"outputs":[],"execution_count":18},{"id":"9YBo6WnNAGXb","cell_type":"markdown","source":"### Layer names are needed for the LoRA configuration.","metadata":{"id":"9YBo6WnNAGXb"}},{"id":"CoC5vYbK_vFd","cell_type":"code","source":"def find_linear_names(model):\n    \"\"\"\n    This function identifies all linear layer names within a model that use 4-bit quantization.\n    Args:\n        model (torch.nn.Module): The PyTorch model to inspect.\n    Returns:\n        list: A list containing the names of all identified linear layers with 4-bit quantization.\n    \"\"\"\n    cls = bnb.nn.Linear4bit\n\n    # Set to store identified layer names\n    lora_module_names = set()\n\n    # Iterate through named modules in the model\n    for name, module in model.named_modules():\n        # Check if the current module is an instance of the 4-bit linear layer class\n        if isinstance(module, cls):\n            names = name.split('.')\n            lora_module_names.add(names[0] if len(names) == 1 else names[-1])\n\n        # Special case: remove 'lm_head' if present\n        if 'lm_head' in lora_module_names:\n            lora_module_names.remove('lm_head')\n    return list(lora_module_names)\n\n# Example usage:\nmodules = find_linear_names(model)\nprint(modules)\n# ['down_proj', 'gate_proj', 'q_proj', 'o_proj', 'up_proj', 'v_proj', 'k_proj']","metadata":{"id":"CoC5vYbK_vFd","trusted":true,"execution":{"iopub.status.busy":"2025-04-20T11:53:23.850581Z","iopub.execute_input":"2025-04-20T11:53:23.850788Z","iopub.status.idle":"2025-04-20T11:53:23.857076Z","shell.execute_reply.started":"2025-04-20T11:53:23.850770Z","shell.execute_reply":"2025-04-20T11:53:23.856322Z"}},"outputs":[{"name":"stdout","text":"['o_proj', 'qkv_proj', 'down_proj', 'gate_up_proj']\n","output_type":"stream"}],"execution_count":19},{"id":"Im9YlEex-3CO","cell_type":"markdown","source":"### LoRA Configuration\nLoRA is a technique that minimizes the number of parameters requiring training during fine-tuning by keeping all original model parameters frozen and introducing a pair of rank decomposition matrices alongside the existing weights. These smaller matrices are designed so that their product matches the dimensions of the weights they modify. The original weights of the LLM remain unchanged, while the smaller matrices are trained using supervised learning. During inference, the two low-rank matrices are multiplied to form a matrix that matches the dimensions of the frozen weights. This matrix is then added to the original weights, effectively updating them in the model.\n\nUse a rank of 8 to train two small rank decomposition matrices with dimensions 8 by A and 8 by B whose product provides a matrix with same dimensions as the frozen weights.  Use task type **SEQ\\_CLS (Sequence Classification)** for text classification tasks\n","metadata":{"id":"Im9YlEex-3CO"}},{"id":"IGhuYXndyJWA","cell_type":"code","source":"lora_config = LoraConfig(\n    r=16,  # 32 to 16 to reduce GPU memory usage\n    lora_alpha=32,  # Dimensionality of the adapter projection\n    target_modules=modules,  # List of modules to apply the LoRA adapter\n    lora_dropout=0.05,  # Dropout rate for the adapter\n    bias=\"none\",  # Bias configuration for the adapter\n    task_type=\"SEQ_CLS\"  # Task type (sequence classification in this case)\n)\n\nmodel = get_peft_model(model, lora_config)\nmodel.print_trainable_parameters()","metadata":{"id":"IGhuYXndyJWA","trusted":true,"execution":{"iopub.status.busy":"2025-04-20T11:53:23.860439Z","iopub.execute_input":"2025-04-20T11:53:23.860690Z","iopub.status.idle":"2025-04-20T11:53:24.623195Z","shell.execute_reply.started":"2025-04-20T11:53:23.860658Z","shell.execute_reply":"2025-04-20T11:53:24.622318Z"}},"outputs":[{"name":"stdout","text":"trainable params: 55,715,840 || all params: 13,851,796,480 || trainable%: 0.4022\n","output_type":"stream"}],"execution_count":20},{"id":"ans0UY5ZvhKi","cell_type":"markdown","source":"### Define trainer arguments","metadata":{"id":"ans0UY5ZvhKi"}},{"id":"ByCLTgaevkTp","cell_type":"code","source":"training_args = TrainingArguments(\n    logging_steps=10,                                                                 # added\n    output_dir=\"epoch_weights\",  # Output directory for checkpoints\n    learning_rate=5e-5,  # Learning rate for the optimizer,                           # 2e-5 to 5e-5\n    per_device_train_batch_size=10,  # Batch size per device                           # 20 to 10 to reduce GPU memory useage\n    per_device_eval_batch_size=10,  # Batch size per device for evaluation             # ditto\n    num_train_epochs=4,  # Number of training epochs from 5 to 1 (list error after 2)\n    weight_decay=0.01,  # Weight decay for regularization\n    evaluation_strategy='epoch',  # Evaluate after each epoch\n    save_strategy=\"epoch\",  # Save model checkpoints after each epoch\n    load_best_model_at_end=True,  # Load the best model based on the chosen metric\n    push_to_hub=False,  # Disable pushing the model to the Hugging Face Hub\n    report_to=\"none\",  # Disable logging to Weight&Bias\n    metric_for_best_model='eval_loss')  # Metric for selecting the best model","metadata":{"id":"ByCLTgaevkTp","trusted":true,"execution":{"iopub.status.busy":"2025-04-20T11:53:24.624543Z","iopub.execute_input":"2025-04-20T11:53:24.624772Z","iopub.status.idle":"2025-04-20T11:53:24.661520Z","shell.execute_reply.started":"2025-04-20T11:53:24.624751Z","shell.execute_reply":"2025-04-20T11:53:24.660750Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\n","output_type":"stream"}],"execution_count":21},{"id":"QTXJYf6ewKoi","cell_type":"markdown","source":"### Early stopping\nAutomate epoch determination to prevent overfitting by stopping training if the validation performance doesn’t improve for a certain number of epochs.","metadata":{"id":"QTXJYf6ewKoi"}},{"id":"hLgKlYc6wMJw","cell_type":"code","source":"early_stop = EarlyStoppingCallback(early_stopping_patience=1, early_stopping_threshold=.0)","metadata":{"id":"hLgKlYc6wMJw","trusted":true,"execution":{"iopub.status.busy":"2025-04-20T11:53:24.662221Z","iopub.execute_input":"2025-04-20T11:53:24.662554Z","iopub.status.idle":"2025-04-20T11:53:24.666340Z","shell.execute_reply.started":"2025-04-20T11:53:24.662528Z","shell.execute_reply":"2025-04-20T11:53:24.665481Z"}},"outputs":[],"execution_count":22},{"id":"px_IYY8LpCC7","cell_type":"markdown","source":"","metadata":{"id":"px_IYY8LpCC7"}},{"id":"gCrHN-eTxY6T","cell_type":"markdown","source":"### Define trainer and train","metadata":{"id":"gCrHN-eTxY6T"}},{"id":"iwsee4u8xcnV","cell_type":"code","source":"# Make sure the model recognizes the pad_token_id\nmodel.config.pad_token_id = tokenizer.pad_token_id\n\ntrainer = Trainer(\n    model=model,  # The LoRA-adapted model\n    args=training_args,  # Training arguments\n    train_dataset=ds_tokenized[\"train\"],  # Training dataset\n    eval_dataset=ds_tokenized[\"val\"],  # Evaluation dataset\n    tokenizer=tokenizer,  # Tokenizer for processing text\n    data_collator=data_collator,  # Data collator for preparing batches\n    compute_metrics=compute_metrics,  # Function to calculate evaluation metrics\n    callbacks=[early_stop],  # Optional early stopping callback\n    #attention_mask=ds_tokenized[\"train\"][\"attention_mask\"]\n)\n\ntrainer.train()","metadata":{"id":"iwsee4u8xcnV","trusted":true,"execution":{"iopub.status.busy":"2025-04-20T11:53:24.667063Z","iopub.execute_input":"2025-04-20T11:53:24.667341Z"}},"outputs":[{"name":"stderr","text":"<ipython-input-23-d7b9ff830b05>:4: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  trainer = Trainer(\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n  return fn(*args, **kwargs)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='16' max='480' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [ 16/480 10:41 < 5:54:22, 0.02 it/s, Epoch 0.12/4]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"},"metadata":{}}],"execution_count":null},{"id":"H2k0jMFtQ5c_","cell_type":"code","source":"# Calculate and print the elapsed time\nelapsed_time = time.time() - start_time\nprint(f\"Time required by training: {elapsed_time:.4f} seconds\")","metadata":{"id":"H2k0jMFtQ5c_","trusted":true},"outputs":[],"execution_count":null},{"id":"50ea0279-1c5d-48c9-a448-ba2b47c09d2d","cell_type":"markdown","source":"### Save model and tokenizer","metadata":{"id":"50ea0279-1c5d-48c9-a448-ba2b47c09d2d"}},{"id":"e7c04828-6aa8-4fb7-b5b0-e1facf23a7ef","cell_type":"code","source":"# Define the directory to save the model and tokenizer\nsave_directory = \"./fine_tuned_bert_model\"\n\n# Save the model and tokenizer\nmodel.save_pretrained(save_directory)\ntokenizer.save_pretrained(save_directory)\n\nprint(f\"Model and tokenizer saved to {save_directory}\")","metadata":{"trusted":true,"id":"e7c04828-6aa8-4fb7-b5b0-e1facf23a7ef"},"outputs":[],"execution_count":null},{"id":"cc806bb9-1fa8-473e-a935-524330d18ed5","cell_type":"markdown","source":"### Starting time for Inference","metadata":{"id":"cc806bb9-1fa8-473e-a935-524330d18ed5"}},{"id":"a0d652e1-ab6a-436a-8c97-58ccf7af4b7d","cell_type":"code","source":"# Set start time for Inference\nstart_time = time.time()","metadata":{"trusted":true,"id":"a0d652e1-ab6a-436a-8c97-58ccf7af4b7d"},"outputs":[],"execution_count":null},{"id":"05f88096-2138-4b71-afff-1db4a8022814","cell_type":"markdown","source":"### Load model and tokenizer","metadata":{"id":"05f88096-2138-4b71-afff-1db4a8022814"}},{"id":"514b726d-5559-486a-8fc7-3e653578a8ea","cell_type":"code","source":"# Reload the model and tokenizer\n#reloaded_model = BertForSequenceClassification.from_pretrained(save_directory)\nreloaded_model = AutoModelForSequenceClassification.from_pretrained(save_directory)\n#reloaded_tokenizer = BertTokenizer.from_pretrained(save_directory)\nreloaded_tokenizer = AutoTokenizer.from_pretrained(save_directory)","metadata":{"trusted":true,"id":"514b726d-5559-486a-8fc7-3e653578a8ea"},"outputs":[],"execution_count":null},{"id":"2ec4e500-7f90-4b98-95cf-94f995728b32","cell_type":"markdown","source":"### Inference on Test data","metadata":{"id":"2ec4e500-7f90-4b98-95cf-94f995728b32"}},{"id":"9f93f3ee-23b1-4f27-98f7-2fb9d6ecedad","cell_type":"code","source":"def predict(input_text):\n    \"\"\"\n    Predicts the sentiment label for a given text input.\n    Args:\n        input_text (str): The text to predict the sentiment for.\n    Returns:\n        float: The predicted probability of the text being positive sentiment.\n    \"\"\"\n    inputs = reloaded_tokenizer(input_text, return_tensors=\"pt\")  # Convert to PyTorch tensors and move to GPU (if available)\n    with torch.no_grad():\n        outputs = reloaded_model(**inputs).logits  # Get the model's output logits\n    y_prob = torch.sigmoid(outputs).tolist()[0]  # Apply sigmoid activation and convert to list\n    #return np.round(y_prob, 5)  # Round the predicted probability to 5 decimal places\n    return y_prob[1]  # Probabilities should be [prob of 0, prob of 1], return prob of 1\n\n# Apply and store predicted probability\ndf_test = pd.DataFrame(ds['test'])\ndf_test['pred_prob'] = df_test['body'].map(predict)\n\n#df_test = pd.DataFrame(ds['test'])\n#df_test['prediction'] = df_test['body'].map(predict)\n#df_test['y_pred'] = df_test['prediction'].apply(lambda x: np.argmax(x, axis=0))","metadata":{"trusted":true,"id":"9f93f3ee-23b1-4f27-98f7-2fb9d6ecedad"},"outputs":[],"execution_count":null},{"id":"ff3633ab-b116-4f2d-90c3-56a9857d1982","cell_type":"code","source":"# Calculate and print the elapsed time\nelapsed_time = time.time() - start_time\nprint(f\"Time required by inference: {elapsed_time:.4f} seconds\")","metadata":{"trusted":true,"id":"ff3633ab-b116-4f2d-90c3-56a9857d1982"},"outputs":[],"execution_count":null},{"id":"d30c2c24-ee7d-4838-81c7-30da9c60a7f9","cell_type":"markdown","source":"### Use ROC to determine best threshold for class 1","metadata":{}},{"id":"b3fbce6f-8437-4316-840c-a9908e3a608e","cell_type":"code","source":"from sklearn.metrics import f1_score, roc_auc_score, precision_recall_curve\n\n# Get true labels and predicted probabilities\ny_true = df_test['label'].values\ny_probs = df_test['pred_prob'].values\n\n# Search for best threshold by maximizing F1-score\nthresholds = np.arange(0.0, 1.01, 0.01)\nf1_scores = [f1_score(y_true, y_probs > t) for t in thresholds]\nbest_threshold = thresholds[np.argmax(f1_scores)]\n\nprint(f\"Best threshold based on F1-score: {best_threshold:.2f}\")\n\n#test_pred = df_test['y_pred'].to_numpy()\n#y_true = df_test['label']\n#y_scores = df_test['prediction'].apply(lambda x: x[1])  # probability of class 1\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"70ef9d77-f5d3-4ddc-9ff3-238a0fbb2fbe","cell_type":"markdown","source":"### Classification metrics on Test data","metadata":{"id":"70ef9d77-f5d3-4ddc-9ff3-238a0fbb2fbe"}},{"id":"740410e6-b98d-41da-a1d3-38e483d21ca0","cell_type":"code","source":"from sklearn.metrics import classification_report\n\n# Convert probabilities to labels based on best threshold\ndf_test['y_pred'] = (df_test['pred_prob'] >= best_threshold).astype(int)\n\n# Print classification report\nprint(classification_report(y_true, df_test['y_pred']))\n\n\n#from sklearn.metrics import classification_report\n#print('classifiation report')\n#print(classification_report(test_pred, df_test['label'].to_numpy(),target_names=label_names))","metadata":{"trusted":true,"id":"740410e6-b98d-41da-a1d3-38e483d21ca0"},"outputs":[],"execution_count":null},{"id":"9a4c7e7e-36bd-42e3-8903-05b52472bc59","cell_type":"markdown","source":"#### AUC","metadata":{"id":"9a4c7e7e-36bd-42e3-8903-05b52472bc59"}},{"id":"4119474e-985b-4a23-ae77-a126c909d2b3","cell_type":"code","source":"import matplotlib.pyplot as plt\n\nprecision, recall, pr_thresholds = precision_recall_curve(y_true, y_probs)\n\nplt.plot(pr_thresholds, precision[:-1], label='Precision')\nplt.plot(pr_thresholds, recall[:-1], label='Recall')\nplt.axvline(best_threshold, color='r', linestyle='--', label=f'Best threshold: {best_threshold:.2f}')\nplt.xlabel(\"Threshold\")\nplt.ylabel(\"Score\")\nplt.title(\"Precision-Recall vs Threshold\")\nplt.legend()\nplt.grid()\nplt.show()\n\n\n# import matplotlib.pyplot as plt\n# from sklearn.metrics import roc_curve, auc\n\n# positive_probs = df_test['prediction'].apply(lambda x: x[1])\n\n# # Compute ROC curve\n# fpr, tpr, _ = roc_curve(test_pred, positive_probs)\n# roc_auc = auc(fpr, tpr)\n\n# # Plot\n# plt.figure(figsize=(8, 6))\n# plt.plot(fpr, tpr, color='blue', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')\n# plt.plot([0, 1], [0, 1], color='grey', linestyle='--')  # Diagonal line for random chance\n# plt.xlim([0.0, 1.0])\n# plt.ylim([0.0, 1.05])\n# plt.xlabel('False Positive Rate')\n# plt.ylabel('True Positive Rate')\n# plt.title('Receiver Operating Characteristic (ROC) Curve')\n# plt.legend(loc=\"lower right\")\n# plt.show()","metadata":{"trusted":true,"id":"4119474e-985b-4a23-ae77-a126c909d2b3"},"outputs":[],"execution_count":null},{"id":"ccc2fedd-e18c-43f7-9887-49430123c2b3","cell_type":"markdown","source":"### Example Inferences","metadata":{"id":"ccc2fedd-e18c-43f7-9887-49430123c2b3"}},{"id":"dccf5df9-9b93-4295-a0fc-9d6ddaf56915","cell_type":"markdown","source":"test_df['pred'] = test_pred\ntest_df.reset_index(level=0)\nprint(test_df[test_df['label']==test_df['pred']].shape)\ntest_df[test_df['label']==test_df['pred']][['text','label','pred']].head(100)","metadata":{"id":"dccf5df9-9b93-4295-a0fc-9d6ddaf56915"}}]}